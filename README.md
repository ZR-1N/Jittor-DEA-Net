<div align="center">

<img src="https://upload.wikimedia.org/wikipedia/commons/c/ca/Nankai_University_logo.svg" height="80px" alt="Nankai University" >
<img src="https://raw.githubusercontent.com/Jittor/jittor/master/docs/images/logo.png" height="80px" alt="Jittor" >

# Jittor-DEA-Net

**DEA-Net: Single image dehazing based on detail-enhanced convolution and content-guided attention (IEEE TIP 2024)**

[![Jittor](https://img.shields.io/badge/Framework-Jittor-EA3323.svg)]([https://cg.cs.tsinghua.edu.cn/jittor/](https://cg.cs.tsinghua.edu.cn/jittor/))
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![GitHub Stars](https://img.shields.io/github/stars/ZR-1N/Jittor-DEA-Net?style=social)](https://github.com/ZR-1N/Jittor-DEA-Net)

[English](#-introduction) | [ç®€ä½“ä¸­æ–‡](#-é¡¹ç›®ç®€ä»‹)

</div>

---

## ğŸ“– Introduction

This repository is an official implementation of **DEA-Net** based on the [Jittor (è®¡å›¾)](https://cg.cs.tsinghua.edu.cn/jittor/) deep learning framework. This project is part of the **"Sprouts Program" at Nankai University**.

DEA-Net proposes a novel detail-enhanced convolution (DEConv) and content-guided attention (CGA) mechanism to effectively restore haze-free images. By leveraging Jittor's **Just-In-Time (JIT) compilation** and **operator fusion**, this implementation achieves competitive training efficiency compared to the PyTorch version while maintaining algorithmic performance.

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯ IEEE TIP 2024 è®ºæ–‡ **DEA-Net** çš„ **Jittor (è®¡å›¾)** ç‰ˆæœ¬å¤ç°ï¼Œå±äº **å—å¼€å¤§å­¦â€œæ–°èŠ½è®¡åˆ’â€** ç ”ç©¶æˆæœã€‚

DEA-Net æå‡ºäº†ä¸€ç§ç»†èŠ‚å¢å¼ºå·ç§¯ï¼ˆDEConvï¼‰å’Œå†…å®¹å¼•å¯¼æ³¨æ„åŠ›ï¼ˆCGAï¼‰æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ¢å¤å»é›¾å›¾åƒã€‚å¾—ç›Šäº Jittor æ¡†æ¶çš„ **å³æ—¶ç¼–è¯‘ (JIT)** å’Œ **ç®—å­èåˆ** æŠ€æœ¯ï¼Œæœ¬é¡¹ç›®åœ¨ä¿æŒåŸè®ºæ–‡ç²¾åº¦çš„åŒæ—¶ï¼Œå®ç°äº†é«˜æ•ˆçš„è®­ç»ƒä¸æ¨ç†ã€‚

---

## ğŸ“Š Model Zoo & Results (æ¨¡å‹åº“ä¸ç»“æœ)

We provide pre-trained models on three mainstream dehazing datasets.
**Note:** The current weights are from the initial training phase (partial epochs), yet they already demonstrate strong performance.
**æ³¨æ„ï¼š** å½“å‰æä¾›çš„æƒé‡å¤„äºè®­ç»ƒåˆæœŸé˜¶æ®µï¼ˆéƒ¨åˆ† Epochï¼‰ï¼Œä½†å·²å±•ç°å‡ºä¼˜ç§€çš„æ€§èƒ½ã€‚

| Dataset | Training Progress | PSNR (dB) | SSIM | Download |
| :--- | :---: | :---: | :---: | :---: |
| **HAZE4K** | 30 Epochs (Partial) | **32.54** | **0.9848** | [Google Drive](#) / [Baidu Netdisk](#) |
| **RESIDE-ITS** | 10 Epochs (Partial) | **35.87** | **0.9893** | [Google Drive](#) / [Baidu Netdisk](#) |
| **RESIDE-OTS** | 10 Epochs (Partial) | **32.71** | **0.9840** | [Google Drive](#) / [Baidu Netdisk](#) |

> *Visual results placeholder*
> ![Results Placeholder](https://via.placeholder.com/800x400?text=Dehazing+Results+Comparison)

---

## âš™ï¸ Installation (å®‰è£…æŒ‡å—)

### Prerequisites
- Linux (Ubuntu 20.04+ recommended)
- Python 3.8+
- NVIDIA GPU + CUDA

### Setup
1. **Clone the repository:**
    ```bash
    git clone https://github.com/ZR-1N/Jittor-DEA-Net.git
    cd Jittor-DEA-Net
    ```

2. **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *Key dependencies: `jittor`, `numpy`, `Pillow`, `matplotlib`, `tqdm`.*

---

## ğŸ“‚ Data Preparation (æ•°æ®å‡†å¤‡)

Please download the datasets and organize them strictly as follows.
è¯·ä¸‹è½½æ•°æ®é›†å¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç›®å½•ç»“æ„æ•´ç†ï¼ˆä»£ç å°†è‡ªåŠ¨è¯†åˆ«è¯¥ç»“æ„ï¼‰ã€‚

**Download Links:** [RESIDE (ITS/OTS)](https://sites.google.com/view/reside-dehaze-datasets/reside-v0)) | [HAZE4K](https://github.com/liuye123321/DMT-Net))

```text
Jittor-DEA-Net/
â”œâ”€â”€ code/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ HAZE4K/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”œâ”€â”€ hazy/   (Contains .png/.jpg images)
â”‚   â”‚   â”‚   â””â”€â”€ clear/  (Contains .png/.jpg images)
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”‚       â”œâ”€â”€ hazy/
â”‚   â”‚       â””â”€â”€ clear/
â”‚   â”œâ”€â”€ ITS/
â”‚   â”‚   â”œâ”€â”€ train/ ... (Same structure as above)
â”‚   â”‚   â””â”€â”€ test/  ...
â”‚   â””â”€â”€ OTS/
â”‚       â”œâ”€â”€ train/ ... (Same structure as above)
â”‚       â””â”€â”€ test/  ...
â””â”€â”€ ...
```

---

## ğŸ”¥ Training (è®­ç»ƒ)

We provide training scripts for different datasets. The code automatically handles `.png` and `.jpg` matching.
æˆ‘ä»¬æä¾›äº†é’ˆå¯¹ä¸åŒæ•°æ®é›†çš„è®­ç»ƒè„šæœ¬ï¼Œä»£ç å·²è‡ªåŠ¨é€‚é… `.png` å’Œ `.jpg` çš„æ–‡ä»¶ååŒ¹é…ã€‚

### 1. Train on HAZE4K
```bash
cd code
CUDA_VISIBLE_DEVICES=0 nohup python train.py \
  --model_name DEA-Net-CR-HAZE4K \
  --dataset HAZE4K \
  --epochs 300 \
  --bs 4 \
  --w_loss_CR 0.1 \
  > training_haze4k.log 2>&1 &
```

### 2. Train on RESIDE-ITS (Indoor)
```bash
cd code
CUDA_VISIBLE_DEVICES=0 nohup python train.py \
  --model_name DEA-Net-CR-ITS \
  --dataset ITS \
  --epochs 300 \
  --bs 4 \
  --w_loss_CR 0.1 \
  > training_its.log 2>&1 &
```

### 3. Train on RESIDE-OTS (Outdoor)
```bash
cd code
CUDA_VISIBLE_DEVICES=0 nohup python train.py \
  --model_name DEA-Net-CR-OTS \
  --dataset OTS \
  --epochs 10 \
  --bs 4 \
  --w_loss_CR 0.1 \
  > training_ots.log 2>&1 &
```

*Training logs and checkpoints will be saved in `experiment/`.*

---

## ğŸ–¼ï¸ Inference (æ¨ç†)

Use `inference_raw.py` to dehaze your own images. The script automatically pads images to support arbitrary resolutions.
ä½¿ç”¨ `inference_raw.py` å¯¹è‡ªå®šä¹‰å›¾åƒè¿›è¡Œå»é›¾ã€‚è„šæœ¬ä¼šè‡ªåŠ¨å¯¹å›¾åƒè¿›è¡Œ Padding ä»¥æ”¯æŒä»»æ„åˆ†è¾¨ç‡ã€‚

```bash
cd code
python3 inference_raw.py \
  --input_dir ../my_hazy_images \
  --output_dir ../my_results \
  --model_path ../experiment/HAZE4K/DEA-Net-CR-HAZE4K/saved_model/best.pk
```

---

## ğŸ”— Acknowledgements & Citation (è‡´è°¢ä¸å¼•ç”¨)

This project is based on the official PyTorch implementation of [DEA-Net](https://github.com/cecret3350/DEA-Net). We thank the authors for their excellent work.

If you find this repository useful, please consider citing the original paper:

```bibtex
@article{chen2023dea,
  title={DEA-Net: Single image dehazing based on detail-enhanced convolution and content-guided attention},
  author={Chen, Zixuan and He, Zewei and Lu, Zhe-Ming},
  journal={IEEE Transactions on Image Processing},
  year={2024},
  volume={33},
  pages={1002-1015}
}
```

## ğŸ“§ Contact

For any questions regarding this Jittor implementation, please contact:
**Shang Wenxuan (å°šæ–‡è½©)**: shangwenxuan.nku@gmail.com
