wsl: 检测到 localhost 代理配置，但未镜像到 WSL。NAT 模式下的 WSL 不支持 localhost 代理。
(base) root@DESKTOP-JGV50N5:~# notepad.exe
(base) root@DESKTOP-JGV50N5:~# cd DEA-NEt
-bash: cd: DEA-NEt: No such file or directory
(base) root@DESKTOP-JGV50N5:~# dir
Anaconda3-2021.05-Linux-x86_64.sh  Jittor-DEA-Net  UNiFMIR    fluoresfm             napari-fluoresfm  project
DEA-Net                            My_Datasets     anaconda3  jittor_test_final.py  nothing           snap
(base) root@DESKTOP-JGV50N5:~# cd DEA-Net
(base) root@DESKTOP-JGV50N5:~/DEA-Net# code .
(base) root@DESKTOP-JGV50N5:~/DEA-Net# cd ..
(base) root@DESKTOP-JGV50N5:~# code .
(base) root@DESKTOP-JGV50N5:~# conda env list
# conda environments:
#
base                  *  /root/anaconda3
abc                      /root/anaconda3/envs/abc
amt                      /root/anaconda3/envs/amt
diffusion                /root/anaconda3/envs/diffusion
napari-fluoresfm         /root/anaconda3/envs/napari-fluoresfm
pytorch_1_10             /root/anaconda3/envs/pytorch_1_10
unifmir                  /root/anaconda3/envs/unifmir
vfi                      /root/anaconda3/envs/vfi

(base) root@DESKTOP-JGV50N5:~# pip list
Package                            Version             Editable project location
---------------------------------- ------------------- --------------------------------------------
alabaster                          0.7.12
anaconda-client                    1.7.2
anaconda-navigator                 2.0.3
anaconda-project                   0.9.1
anyio                              2.2.0
appdirs                            1.4.4
argh                               0.26.2
argon2-cffi                        20.1.0
asn1crypto                         1.4.0
astroid                            2.5
astropy                            4.2.1
astunparse                         1.6.3
async-generator                    1.10
atomicwrites                       1.4.0
attrs                              20.3.0
autopep8                           1.5.6
Babel                              2.9.0
backcall                           0.2.0
backports.functools-lru-cache      1.6.4
backports.shutil-get-terminal-size 1.0.0
backports.tempfile                 1.0
backports.weakref                  1.0.post1
beautifulsoup4                     4.9.3
bitarray                           2.1.0
bkcharts                           0.2
black                              19.10b0
bleach                             3.3.0
bokeh                              2.3.2
boto                               2.49.0
Bottleneck                         1.3.2
brotlipy                           0.7.0
certifi                            2020.12.5
cffi                               1.14.5
chardet                            4.0.0
click                              7.1.2
cloudpickle                        1.6.0
clyent                             1.2.2
colorama                           0.4.4
conda                              4.10.1
conda-build                        3.21.4
conda-content-trust                0+unknown
conda-package-handling             1.7.3
conda-repo-cli                     1.0.4
conda-token                        0.3.0
conda-verify                       3.4.2
contextlib2                        0.6.0.post1
cryptography                       3.4.7
cupy-cuda101                       9.6.0
cycler                             0.10.0
Cython                             0.29.23
cytoolz                            0.11.0
dask                               2021.4.0
decorator                          5.0.6
defusedxml                         0.7.1
diff-match-patch                   20200713
distributed                        2021.4.1
docutils                           0.17.1
einops                             0.8.1
entrypoints                        0.3
et-xmlfile                         1.0.1
fastcache                          1.1.0
fastrlock                          0.8.2
filelock                           3.0.12
flake8                             3.9.0
Flask                              1.1.2
fsspec                             0.9.0
future                             0.18.2
gevent                             21.1.2
git-filter-repo                    2.47.0
glob2                              0.7
gmpy2                              2.0.8
greenlet                           1.0.0
h5py                               2.10.0
HeapDict                           1.0.1
html5lib                           1.1
idna                               2.10
imageio                            2.9.0
imagesize                          1.2.0
importlib-metadata                 3.10.0
iniconfig                          1.1.1
intervaltree                       3.1.0
ipykernel                          5.3.4
ipython                            7.22.0
ipython-genutils                   0.2.0
ipywidgets                         7.6.3
isort                              5.8.0
itsdangerous                       1.1.0
jdcal                              1.4.1
jedi                               0.17.2
jeepney                            0.6.0
Jinja2                             2.11.3
jittor                             1.3.10.0
joblib                             1.0.1
json5                              0.9.5
jsonschema                         3.2.0
jupyter                            1.0.0
jupyter-client                     6.1.12
jupyter-console                    6.4.0
jupyter-core                       4.7.1
jupyter-packaging                  0.7.12
jupyter-server                     1.4.1
jupyterlab                         3.0.14
jupyterlab-pygments                0.1.2
jupyterlab-server                  2.4.0
jupyterlab-widgets                 1.0.0
keyring                            22.3.0
kiwisolver                         1.3.1
lazy-object-proxy                  1.6.0
libarchive-c                       2.9
llvmlite                           0.36.0
locket                             0.2.1
lxml                               4.6.3
MarkupSafe                         1.1.1
matplotlib                         3.3.4
mccabe                             0.6.1
mistune                            0.8.4
mkl-fft                            1.3.0
mkl-random                         1.2.1
mkl-service                        2.3.0
mock                               4.0.3
more-itertools                     8.7.0
mpmath                             1.2.1
msgpack                            1.0.2
multipledispatch                   0.6.0
mypy-extensions                    0.4.3
navigator-updater                  0.2.1
nbclassic                          0.2.6
nbclient                           0.5.3
nbconvert                          6.0.7
nbformat                           5.1.3
nest-asyncio                       1.5.1
networkx                           2.5
nltk                               3.6.1
nose                               1.3.7
notebook                           6.3.0
numba                              0.53.1
numexpr                            2.7.3
numpy                              1.20.1
numpydoc                           1.1.0
olefile                            0.46
opencv-python                      4.6.0.66
openpyxl                           3.0.7
packaging                          20.9
pandas                             1.2.4
pandocfilters                      1.4.3
parso                              0.7.0
partd                              1.2.0
path                               15.1.2
pathlib2                           2.3.5
pathspec                           0.7.0
patsy                              0.5.1
pep8                               1.7.1
pexpect                            4.8.0
pickleshare                        0.7.5
Pillow                             9.2.0
pip                                25.0.1
pkginfo                            1.7.0
pluggy                             0.13.1
ply                                3.11
prometheus-client                  0.10.1
prompt-toolkit                     3.0.17
psutil                             5.8.0
ptyprocess                         0.7.0
py                                 1.10.0
pycocotools                        2.0.7
pycodestyle                        2.6.0
pycosat                            0.6.3
pycparser                          2.20
pycurl                             7.43.0.6
pydocstyle                         6.0.0
pyerfa                             1.7.3
pyflakes                           2.2.0
Pygments                           2.8.1
pylint                             2.7.4
pyls-black                         0.4.6
pyls-spyder                        0.3.2
pyodbc                             5.2.0
pyOpenSSL                          20.0.1
pyparsing                          2.4.7
pyrsistent                         0.17.3
PySocks                            1.7.1
pytest                             6.2.3
python-dateutil                    2.8.1
python-jsonrpc-server              0.4.0
python-language-server             0.36.2
pytz                               2021.1
PyWavelets                         1.1.1
pyxdg                              0.27
PyYAML                             5.4.1
pyzmq                              20.0.0
QDarkStyle                         2.8.1
QtAwesome                          1.0.2
qtconsole                          5.0.3
QtPy                               1.9.0
regex                              2021.4.4
requests                           2.25.1
rope                               0.18.0
Rtree                              0.9.7
ruamel-yaml-conda                  0.15.100
scikit-image                       0.18.1
scikit-learn                       0.24.1
scipy                              1.6.2
seaborn                            0.11.1
SecretStorage                      3.3.1
segment-anything                   1.0                 /root/project/Segment-and-Track-Anything/sam
Send2Trash                         1.5.0
setuptools                         52.0.0.post20210125
simplegeneric                      0.8.1
singledispatch                     0.0.0
sip                                4.19.13
six                                1.15.0
sniffio                            1.2.0
snowballstemmer                    2.1.0
some-package                       0.1
sortedcollections                  2.1.0
sortedcontainers                   2.3.0
soupsieve                          2.2.1
Sphinx                             4.0.1
sphinxcontrib-applehelp            1.0.2
sphinxcontrib-devhelp              1.0.2
sphinxcontrib-htmlhelp             1.0.3
sphinxcontrib-jsmath               1.0.1
sphinxcontrib-qthelp               1.0.3
sphinxcontrib-serializinghtml      1.1.4
sphinxcontrib-websupport           1.2.4
spyder                             4.2.5
spyder-kernels                     1.10.2
SQLAlchemy                         1.4.15
statsmodels                        0.12.2
sympy                              1.8
tables                             3.6.1
tblib                              1.7.0
terminado                          0.9.4
testpath                           0.4.4
textdistance                       4.2.1
threadpoolctl                      2.1.0
three-merge                        0.1.1
tifffile                           2020.10.1
toml                               0.10.2
toolz                              0.11.1
torch                              1.13.1+cu117
torchvision                        0.14.1+cu117
tornado                            6.1
tqdm                               4.59.0
traitlets                          5.0.5
typed-ast                          1.4.2
typing-extensions                  3.7.4.3
ujson                              4.0.2
unicodecsv                         0.14.1
urllib3                            1.26.4
watchdog                           1.0.2
wcwidth                            0.2.5
webencodings                       0.5.1
Werkzeug                           1.0.1
wheel                              0.36.2
widgetsnbextension                 3.5.1
wrapt                              1.12.1
wurlitzer                          2.1.0
xlrd                               2.0.1
XlsxWriter                         1.3.8
xlwt                               1.3.0
xmltodict                          0.12.0
yapf                               0.31.0
zict                               2.0.0
zipp                               3.4.1
zope.event                         4.5.0
zope.interface                     5.3.0
(base) root@DESKTOP-JGV50N5:~# conda activate pytorch_1_10
(pytorch_1_10) root@DESKTOP-JGV50N5:~# pip list
Package             Version
------------------- -----------
click               8.1.8
contourpy           1.1.1
cycler              0.12.1
einops              0.8.1
fonttools           4.57.0
git-filter-repo     2.47.0
importlib_resources 6.4.5
kiwisolver          1.4.7
matplotlib          3.7.5
mkl-fft             1.3.8
mkl-random          1.2.4
mkl-service         2.4.0
numpy               1.24.3
opencv-python       4.6.0.66
packaging           25.0
pillow              10.4.0
pip                 24.2
pyparsing           3.1.4
python-dateutil     2.9.0.post0
setuptools          75.1.0
six                 1.17.0
svgwrite            1.4.3
torch               1.10.0
torchaudio          0.10.0
torchvision         0.11.0
tqdm                4.67.1
Tree                0.2.4
typing_extensions   4.11.0
wheel               0.44.0
zipp                3.20.2
(pytorch_1_10) root@DESKTOP-JGV50N5:~# conda deactivate
(base) root@DESKTOP-JGV50N5:~# conda create -n jittor_env python=3.8 -y
Collecting package metadata (current_repodata.json): done
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: done


==> WARNING: A newer version of conda exists. <==
  current version: 4.10.1
  latest version: 25.11.1

Please update conda by running

    $ conda update -n base -c defaults conda



## Package Plan ##

  environment location: /root/anaconda3/envs/jittor_env

  added / updated specs:
    - python=3.8


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    ca-certificates-2025.12.2  |       h06a4308_0         125 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
    ------------------------------------------------------------
                                           Total:         125 KB

The following NEW packages will be INSTALLED:

  _libgcc_mutex      anaconda/pkgs/main/linux-64::_libgcc_mutex-0.1-main
  _openmp_mutex      anaconda/pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu
  ca-certificates    anaconda/pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0
  ld_impl_linux-64   anaconda/pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2
  libffi             anaconda/pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1
  libgcc             anaconda/pkgs/main/linux-64::libgcc-15.2.0-h69a1729_7
  libgcc-ng          anaconda/pkgs/main/linux-64::libgcc-ng-15.2.0-h166f726_7
  libgomp            anaconda/pkgs/main/linux-64::libgomp-15.2.0-h4751f2c_7
  libstdcxx          anaconda/pkgs/main/linux-64::libstdcxx-15.2.0-h39759b7_7
  libstdcxx-ng       anaconda/pkgs/main/linux-64::libstdcxx-ng-15.2.0-hc03a8fd_7
  libxcb             anaconda/pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0
  libzlib            anaconda/pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0
  ncurses            anaconda/pkgs/main/linux-64::ncurses-6.5-h7934f7d_0
  openssl            anaconda/pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0
  pip                anaconda/pkgs/main/linux-64::pip-24.2-py38h06a4308_0
  pthread-stubs      anaconda/pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1
  python             anaconda/pkgs/main/linux-64::python-3.8.20-he870216_0
  readline           anaconda/pkgs/main/linux-64::readline-8.3-hc2a1206_0
  setuptools         anaconda/pkgs/main/linux-64::setuptools-75.1.0-py38h06a4308_0
  sqlite             anaconda/pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0
  tk                 anaconda/pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0
  wheel              anaconda/pkgs/main/linux-64::wheel-0.44.0-py38h06a4308_0
  xorg-libx11        anaconda/pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1
  xorg-libxau        anaconda/pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0
  xorg-libxdmcp      anaconda/pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0
  xorg-xorgproto     anaconda/pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1
  xz                 anaconda/pkgs/main/linux-64::xz-5.6.4-h5eee18b_1
  zlib               anaconda/pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0



Downloading and Extracting Packages
ca-certificates-2025 | 125 KB    | ############################################################################# | 100%
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
#
# To activate this environment, use
#
#     $ conda activate jittor_env
#
# To deactivate an active environment, use
#
#     $ conda deactivate

(base) root@DESKTOP-JGV50N5:~# conda activate jittor_env
(jittor_env) root@DESKTOP-JGV50N5:~# pip install jittor
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Collecting jittor
  Using cached jittor-1.3.10.0-py3-none-any.whl
Collecting numpy<2.0 (from jittor)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/98/5d/5738903efe0ecb73e51eb44feafba32bdba2081263d40c5043568ff60faf/numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)
Collecting tqdm (from jittor)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl (78 kB)
Collecting pillow (from jittor)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fb/ad/435fe29865f98a8fbdc64add8875a6e4f8c97749a93577a8919ec6f32c64/pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 2.3 MB/s eta 0:00:00
Collecting astunparse (from jittor)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/envs/jittor_env/lib/python3.8/site-packages (from astunparse->jittor) (0.44.0)
Collecting six<2.0,>=1.6.1 (from astunparse->jittor)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b7/ce/149a00dd41f10bc29e5921b496af8b574d8413afcd5e30dfa0ed46c2cc5e/six-1.17.0-py2.py3-none-any.whl (11 kB)
Installing collected packages: tqdm, six, pillow, numpy, astunparse, jittor
Successfully installed astunparse-1.6.3 jittor-1.3.10.0 numpy-1.24.4 pillow-10.4.0 six-1.17.0 tqdm-4.67.1
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
(jittor_env) root@DESKTOP-JGV50N5:~# pip install numpy opencv-python matplotlib pillow tqdm einops
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Requirement already satisfied: numpy in ./anaconda3/envs/jittor_env/lib/python3.8/site-packages (1.24.4)
Collecting opencv-python
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/68/1f/795e7f4aa2eacc59afa4fb61a2e35e510d06414dd5a802b51a012d691b37/opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 MB 1.8 MB/s eta 0:00:00
Collecting matplotlib
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/30/33/cc27211d2ffeee4fd7402dca137b6e8a83f6dcae3d4be8d0ad5068555561/matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)
Requirement already satisfied: pillow in ./anaconda3/envs/jittor_env/lib/python3.8/site-packages (10.4.0)
Requirement already satisfied: tqdm in ./anaconda3/envs/jittor_env/lib/python3.8/site-packages (4.67.1)
Collecting einops
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/87/62/9773de14fe6c45c23649e98b83231fffd7b9892b6cf863251dc2afa73643/einops-0.8.1-py3-none-any.whl (64 kB)
Collecting contourpy>=1.0.1 (from matplotlib)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/8e/71/7f20855592cc929bc206810432b991ec4c702dc26b0567b132e52c85536f/contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)
Collecting cycler>=0.10 (from matplotlib)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl (8.3 kB)
Collecting fonttools>=4.22.0 (from matplotlib)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a5/0e/b6314a09a4d561aaa7e09de43fa700917be91e701f07df6178865962666c/fonttools-4.57.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)
Collecting kiwisolver>=1.0.1 (from matplotlib)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/76/36/ae40d7a3171e06f55ac77fe5536079e7be1d8be2a8210e08975c7f9b4d54/kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)
Collecting packaging>=20.0 (from matplotlib)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/20/12/38679034af332785aac8774540895e234f4d07f7545804097de4b666afd8/packaging-25.0-py3-none-any.whl (66 kB)
Collecting pyparsing>=2.3.1 (from matplotlib)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e5/0c/0e3c05b1c87bb6a1c76d281b0f35e78d2d80ac91b5f8f524cebf77f51049/pyparsing-3.1.4-py3-none-any.whl (104 kB)
Collecting python-dateutil>=2.7 (from matplotlib)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Collecting importlib-resources>=3.2.0 (from matplotlib)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl (36 kB)
Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/62/8b/5ba542fa83c90e09eac972fc9baca7a88e7e7ca4b221a89251954019308b/zipp-3.20.2-py3-none-any.whl (9.2 kB)
Requirement already satisfied: six>=1.5 in ./anaconda3/envs/jittor_env/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)
Installing collected packages: zipp, python-dateutil, pyparsing, packaging, opencv-python, kiwisolver, fonttools, einops, cycler, contourpy, importlib-resources, matplotlib
Successfully installed contourpy-1.1.1 cycler-0.12.1 einops-0.8.1 fonttools-4.57.0 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.7.5 opencv-python-4.12.0.88 packaging-25.0 pyparsing-3.1.4 python-dateutil-2.9.0.post0 zipp-3.20.2
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
(jittor_env) root@DESKTOP-JGV50N5:~# pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
Looking in indexes: https://download.pytorch.org/whl/cpu
Collecting torch
  Downloading https://download.pytorch.org/whl/cpu/torch-2.4.1%2Bcpu-cp38-cp38-linux_x86_64.whl (194.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.9/194.9 MB 873.6 kB/s eta 0:00:00
Collecting torchvision
  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.19.1%2Bcpu-cp38-cp38-linux_x86_64.whl (1.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 541.7 kB/s eta 0:00:00
Collecting filelock (from torch)
  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)
Collecting typing-extensions>=4.8.0 (from torch)
  Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting sympy (from torch)
  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch)
  Using cached networkx-3.1-py3-none-any.whl.metadata (5.3 kB)
Collecting jinja2 (from torch)
  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch)
  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)
Requirement already satisfied: numpy in ./anaconda3/envs/jittor_env/lib/python3.8/site-packages (from torchvision) (1.24.4)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./anaconda3/envs/jittor_env/lib/python3.8/site-packages (from torchvision) (10.4.0)
INFO: pip is looking at multiple versions of typing-extensions to determine which version is compatible with other requirements. This could take a while.
Collecting typing-extensions>=4.8.0 (from torch)
  Downloading https://download.pytorch.org/whl/typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)
  Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch)
  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)
  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Downloading filelock-3.16.1-py3-none-any.whl (16 kB)
Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)
Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached networkx-3.1-py3-none-any.whl (2.1 MB)
Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 668.1 kB/s eta 0:00:00
Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 267.9 kB/s eta 0:00:00
Installing collected packages: mpmath, typing-extensions, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision
Successfully installed MarkupSafe-2.1.5 filelock-3.16.1 fsspec-2025.3.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.1 sympy-1.13.3 torch-2.4.1+cpu torchvision-0.19.1+cpu typing-extensions-4.12.2
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
(jittor_env) root@DESKTOP-JGV50N5:~# g++ --version
g++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

(jittor_env) root@DESKTOP-JGV50N5:~# python
Python 3.8.20 (default, Oct  3 2024, 15:24:27)
[GCC 11.2.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import jittor as jt
[i 1219 13:01:46.866530 92 lock.py:85] Create lock file:/root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/jittor.lock
[i 1219 13:01:46.874098 92 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:01:46.875714 92 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:01:46.875775 92 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:01:46.925572 92 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:01:46.925772 92 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python []
Python 3.8.20 (default, Oct  3 2024, 15:24:27)
[GCC 11.2.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> print(f"Use CUDA: {jt.flags.use_cuda}")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'jt' is not defined
>>> import jittor as jt
CUDA: {jt.flags.use_cuda}")[i 1219 13:02:31.925128 52 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:02:31.927170 52 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:02:31.927241 52 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:02:31.980437 52 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:02:31.986208 52 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:02:32.006183 52 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:02:32.068229 52 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:02:32.087015 52 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default/cu12.2.140
[i 1219 13:02:32.088041 52 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default/cu12.2.140/jit
[i 1219 13:02:32.088504 52 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default/cu12.2.140/obj_files
[i 1219 13:02:32.088646 52 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default/cu12.2.140/gen
[i 1219 13:02:32.088784 52 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default/cu12.2.140/tmp
[i 1219 13:02:32.089305 52 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default/cu12.2.140/checkpoints
[i 1219 13:02:43.154711 28 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
Compiling jittor_core(151/151) used: 15.419s eta: 0.000s
[i 1219 13:02:58.762036 28 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:02:58.944072 28 init.cc:63] Found cuda archs: [86,]
[i 1219 13:02:59.701110 28 compile_extern.py:388] Downloading cutt...
[i 1219 13:02:59.707681 28 compile_extern.py:401] installing cutt...
Compiling libcutt(9/9) used: 4.281s eta: 0.000s
[i 1219 13:03:04.060015 28 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default/cu12.2.140/custom_ops
[i 1219 13:03:06.246555 28 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default/cu12.2.140/cuda
Compiling gen_ops_cudnn_rnn_cudnn_conv_backward_x_cudnn_conv___hash2da7f6(16/16) used: 2.348s eta: 0.000s
>>> print(f"Use CUDA: {jt.flags.use_cuda}")
Use CUDA: 0
>>> jt.flags.use_cuda = 1
[i 1219 13:03:53.390011 28 cuda_flags.cc:55] CUDA enabled.
>>> print(f"Now Use CUDA: {jt.flags.use_cuda}")
Now Use CUDA: 1
>>> a = jt.rand(1000, 1000)
and(1000, 1000)>>> b = jt.rand(1000, 1000)
>>> c = a @ b
>>> print(f"Calculation result shape: {c.shape}")
Calculation result shape: [1000,1000,]
>>> print("CUDA test passed!")
CUDA test passed!
>>> exit()
(jittor_env) root@DESKTOP-JGV50N5:~# # 1. 转换 HAZE4K
ython3 convert_t(jittor_env) root@DESKTOP-JGV50N5:~# python3 convert_torch_to_jittor.py --input trained_models/PSNR3426_SSIM9885.pth --output trained_models/HAZE4K_fused.pkl
 ITS
python3 convert_torch_to_jittor.py --input trained_models/PSNR4131_SSIM9945.pth --output trained_models/ITS_fused.pkl

# 3. 转换 OTS
python3 convert_torch_to_jittor.py --input trained_models/PSNR3659_SSIM9897.pth --output trained_models/OTS_fused.pklpython3: can't open file 'convert_torch_to_jittor.py': [Errno 2] No such file or directory
(jittor_env) root@DESKTOP-JGV50N5:~#
(jittor_env) root@DESKTOP-JGV50N5:~# # 2. 转换 ITS
(jittor_env) root@DESKTOP-JGV50N5:~# python3 convert_torch_to_jittor.py --input trained_models/PSNR4131_SSIM9945.pth --output trained_models/ITS_fused.pkl
python3: can't open file 'convert_torch_to_jittor.py': [Errno 2] No such file or directory
(jittor_env) root@DESKTOP-JGV50N5:~#
(jittor_env) root@DESKTOP-JGV50N5:~# # 3. 转换 OTS
(jittor_env) root@DESKTOP-JGV50N5:~# python3 convert_torch_to_jittor.py --input trained_models/PSNR3659_SSIM9897.pth --output trained_models/OTS_fused.pkl
python3: can't open file 'convert_torch_to_jittor.py': [Errno 2] No such file or directory
(jittor_env) root@DESKTOP-JGV50N5:~# cd Jittor-DEA-Net
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# # 1. 转换 HAZE4K
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# python3 convert_torch_to_jittor.py --input trained_models/PSNR3426_SSIM9885.pth --output trained_models/HAZE4K_fused.pkl
 ITS
python3 convert_torch_to_jittor.py --input trained_models/PSNR4131_SSIM9945.pth --output trained_models/ITS_fused.pkl

# 3. 转换 OTS
python3 convert_torch_to_jittor.py --input trained_models/PSNR3659_SSIM9897.pth --output trained_models/OTS_fused.pklpython3: can't open file 'convert_torch_to_jittor.py': [Errno 2] No such file or directory
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net#
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# # 2. 转换 ITS
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# python3 convert_torch_to_jittor.py --input trained_models/PSNR4131_SSIM9945.pth --output trained_models/ITS_fused.pkl
python3: can't open file 'convert_torch_to_jittor.py': [Errno 2] No such file or directory
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net#
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# # 3. 转换 OTS
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# python3 convert_torch_to_jittor.py --input trained_models/PSNR3659_SSIM9897.pth --output trained_models/OTS_fused.pkl
python3: can't open file 'convert_torch_to_jittor.py': [Errno 2] No such file or directory
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# dir
CONTRIBUTING.md  LICENSE  README.md  code  dataset  fig  requirements.txt  trained_models
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# cd trained_models
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/trained_models# dir
HAZE4K  ITS  OTS  README.md
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/trained_models# cd HAZE4K
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/trained_models/HAZE4K# dir
PSNR3426_SSIM9885.pth
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/trained_models/HAZE4K# cd ..
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/trained_models# cd ..
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# cat << 'EOF' > convert_torch_to_jittor.py
> import torch
> import jittor as jt
t os
import argp> import os
> import argparse
> from collections import OrderedDict
>
> # -------------------------------------------------------------------------
> # 数学融合逻辑 (适配 PyTorch Tensor 输入)
> # -------------------------------------------------------------------------
> # 尝试导入 einops，如果没有则报错提示安装
> try:
>     from einops.layers.torch import Rearrange
> except ImportError:
>     print("Error: Please install einops first: pip install einops")
>     exit(1)
>
> def convert_cdc(w):
>     conv_weight = w
>     conv_shape = conv_weight.shape
>     conv_weight = Rearrange('c_in c_out k1 k2 -> c_in c_out (k1 k2)')(conv_weight)
>     conv_weight_cd = torch.zeros(conv_shape[0], conv_shape[1], 3 * 3)
>     conv_weight_cd[:, :, :] = conv_weight[:, :, :]
>     conv_weight_cd[:, :, 4] = conv_weight[:, :, 4] - conv_weight[:, :, :].sum(2)
conv_weight_cd = Rearrange('c_in>     conv_weight_cd = Rearrange('c_in c_out (k1 k2) -> c_in c_out k1 k2', k1=conv_shape[2], k2=conv_shape[3])(conv_weight_cd)
>     return conv_weight_cd
>
> def convert_hdc(w):
>     conv_weight = w
>     conv_shape = conv_weight.shape
>     conv_weight_hd = torch.zeros(conv_shape[0], conv_shape[1], 3 * 3)
>     conv_weight_hd[:, :, [0, 3, 6]] = conv_weight[:, :, :]
>     conv_weight_hd[:, :, [2, 5, 8]] = -conv_weight[:, :, :]
>     conv_weight_hd = Rearrange('c_in c_out (k1 k2) -> c_in c_out k1 k2', k1=conv_shape[2], k2=conv_shape[2])(conv_weight_hd)
>     return conv_weight_hd
>
vdc(w):
    conv> def convert_vdc(w):
>     conv_weight = w
>     conv_shape = conv_weight.shape
>     conv_weight_vd = torch.zeros(conv_shape[0], conv_shape[1], 3 * 3)
>     conv_weight_vd[:, :, [0, 1, 2]] = conv_weight[:, :, :]
>     conv_weight_vd[:, :, [6, 7, 8]] = -conv_weight[:, :, :]
>     conv_weight_vd = Rearrange('c_in c_out (k1 k2) -> c_in c_out k1 k2', k1=conv_shape[2], k2=conv_shape[2])(conv_weight_vd)
>     return conv_weight_vd
>
> def convert_adc(w):
>     conv_weight = w
>     conv_shape = conv_weight.shape
>     conv_weight = Rearrange('c_in c_out k1 k2 -> c_in c_out (k1 k2)')(conv_weight)
>     conv_weight_ad = conv_weight - conv_weight[:, :, [3, 0, 1, 6, 4, 2, 7, 8, 5]]
>     conv_weight_ad = Rearrange('c_in c_out (k1 k2) -> c_in c_out k1 k2', k1=conv_shape[2], k2=conv_shape[3])(conv_weight_ad)
>     return conv_weight_ad
>
> # -------------------------------------------------------------------------
> # 主转换逻辑
> # -------------------------------------------------------------------------
> def convert(pth_path, save_path):
>     print(f"Loading PyTorch checkpoint: {pth_path}")
>     if not os.path.exists(pth_path):
>         print(f"Error: File not found: {pth_path}")
>         return
>
>     # 加载 PyTorch 权重到 CPU
>     try:
>         ckp = torch.load(pth_path, map_location='cpu')
>     except Exception as e:
>         print(f"Error loading {pth_path}: {e}")
>         return
>
>     # 1. 提取 state_dict
>     if 'model' in ckp:
>         ckp = ckp['model']
>
>     # 2. 去除 module. 前缀
>     stripped_ckp = OrderedDict()
>     for k, v in ckp.items():
>         name = k.replace('module.', '')
>         stripped_ckp[name] = v
>
>     ckp = stripped_ckp
>     final_dict = {}
>
>     # 3. 遍历并融合权重
>     keys_to_process = list(ckp.keys())
>     processed_bases = set()
>
tarting fusion p>     print("Starting fusion process...")
>     for key in keys_to_process:
>         if 'conv1_5' in key: # 以最后一个分支为触发点
>             base_key = key.split('conv1_5')[0]
>             if base_key in processed_bases: continue
>
>             # 找到5个分支的权重
>             w_cdc = convert_cdc(ckp[base_key + 'conv1_1.weight'])
>             w_hdc = convert_hdc(ckp[base_key + 'conv1_2.weight'])
>             w_vdc = convert_vdc(ckp[base_key + 'conv1_3.weight'])
>             w_adc = convert_adc(ckp[base_key + 'conv1_4.weight'])
>             w_vc  = ckp[base_key + 'conv1_5.weight']
>
      w_final = >             w_final = w_cdc + w_hdc + w_vdc + w_adc + w_vc
>
>             b_cdc = ckp[base_key + 'conv1_1.bias']
>             b_hdc = ckp[base_key + 'conv1_2.bias']
>             b_vdc = ckp[base_key + 'conv1_3.bias']
>             b_adc = ckp[base_key + 'conv1_4.bias']
>             b_vc  = ckp[base_key + 'conv1_5.bias']
>
>             b_final = b_cdc + b_hdc + b_vdc + b_adc + b_vc
>
>             # 存入新字典，改名为 standard conv1
>             final_dict[base_key + 'conv1.weight'] = w_final.numpy() # 转为 numpy 传给 Jittor
>             final_dict[base_key + 'conv1.bias'] = b_final.numpy()

           >
>             processed_bases.add(base_key)
>             # print(f"Fused branch: {base_key}") # 减少刷屏
>
>         elif any(x in key for x in ['conv1_1', 'conv1_2', 'conv1_3', 'conv1_4']):
>             # 这些是中间分支，已经被合并了，跳过
      continue
 >             continue
>         else:
>             # 普通层，直接复制 (注意转 numpy)
>             if isinstance(ckp[key], torch.Tensor):
>                 final_dict[key] = ckp[key].numpy()
>             else:
>                 final_dict[key] = ckp[key]
>
>     # 4. 保存为 Jittor 格式
>     os.makedirs(os.path.dirname(save_path), exist_ok=True)
>     jt.save(final_dict, save_path)
>     print(f"Success! Saved Jittor model to: {save_path}")
>
> if __name__ == '__main__':
>     parser = argparse.ArgumentParser()
>     parser.add_argument('--input', type=str, required=True, help='Input .pth file')
>     parser.add_argument('--output', type=str, required=True, help='Output .pkl file')
>     args = parser.parse_args()
>
>     convert(args.input, args.output)
> EOF
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# dir
CONTRIBUTING.md  LICENSE  README.md  code  convert_torch_to_jittor.py  dataset  fig  requirements.txt  trained_models
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# python3 convert_torch_to_jittor.py --input trained_models/HAZE4K/PSNR3426_SSIM9885.pth --output trained_models/HAZE4K/HAZE4K_fused.pkl
[i 1219 13:10:11.535514 88 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:10:11.538396 88 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:10:11.538493 88 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:10:11.576118 88 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:10:11.576290 88 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['convert_torch_to_jittor.py', '--input', 'trained_models/HAZE4K/PSNR3426_SSIM9885.pth', '--output', 'trained_models/HAZE4K/HAZE4K_fused.pkl']
[i 1219 13:10:12.178516 00 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:10:12.181580 00 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:10:12.181626 00 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:10:12.213508 00 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:10:12.216859 00 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:10:12.231791 00 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:10:12.284722 00 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:10:12.451968 00 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:10:12.505535 00 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:10:12.682618 00 init.cc:63] Found cuda archs: [86,]
Loading PyTorch checkpoint: trained_models/HAZE4K/PSNR3426_SSIM9885.pth
convert_torch_to_jittor.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckp = torch.load(pth_path, map_location='cpu')
Starting fusion process...
Success! Saved Jittor model to: trained_models/HAZE4K/HAZE4K_fused.pkl
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# python3 convert_torch_to_jittor.py --input trained_models/ITS/PSNR4131_SSIM9945.pth --output trained_models/ITS/ITS_fused.pkl
[i 1219 13:10:21.639535 08 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:10:21.642113 08 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:10:21.642157 08 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:10:21.685469 08 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:10:21.685634 08 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['convert_torch_to_jittor.py', '--input', 'trained_models/ITS/PSNR4131_SSIM9945.pth', '--output', 'trained_models/ITS/ITS_fused.pkl']
[i 1219 13:10:22.302323 60 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:10:22.305431 60 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:10:22.305475 60 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:10:22.346509 60 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:10:22.351014 60 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:10:22.374938 60 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:10:22.433379 60 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:10:22.603540 60 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:10:22.665924 60 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:10:22.863131 60 init.cc:63] Found cuda archs: [86,]
Loading PyTorch checkpoint: trained_models/ITS/PSNR4131_SSIM9945.pth
convert_torch_to_jittor.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckp = torch.load(pth_path, map_location='cpu')
Starting fusion process...
Success! Saved Jittor model to: trained_models/ITS/ITS_fused.pkl
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# # 同理
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# python3 convert_torch_to_jittor.py --input trained_models/OTS/PSNR3659_SSIM9897.pth --output trained_models/OTS/OTS_fused.pkl
[i 1219 13:10:36.574329 92 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:10:36.577358 92 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:10:36.577405 92 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:10:36.613970 92 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:10:36.614143 92 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['convert_torch_to_jittor.py', '--input', 'trained_models/OTS/PSNR3659_SSIM9897.pth', '--output', 'trained_models/OTS/OTS_fused.pkl']
[i 1219 13:10:37.222452 52 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:10:37.225543 52 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:10:37.225589 52 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:10:37.261430 52 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:10:37.265214 52 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:10:37.280046 52 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:10:37.333258 52 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:10:37.500416 52 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:10:37.558402 52 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:10:37.787231 52 init.cc:63] Found cuda archs: [86,]
Loading PyTorch checkpoint: trained_models/OTS/PSNR3659_SSIM9897.pth
convert_torch_to_jittor.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckp = torch.load(pth_path, map_location='cpu')
Starting fusion process...
Success! Saved Jittor model to: trained_models/OTS/OTS_fused.pkl
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# python3 eval.py \
>   --dataset HAZE4K \
>   --model_name DEA-Net-CR \
>   --pre_trained_model HAZE4K/HAZE4K_fused.pkl \
>   --save_infer_results
python3: can't open file 'eval.py': [Errno 2] No such file or directory
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# dir
CONTRIBUTING.md  LICENSE  README.md  code  convert_torch_to_jittor.py  dataset  fig  requirements.txt  trained_models
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net# cd code
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# python3 eval.py \
>   --dataset HAZE4K \
>   --model_name DEA-Net-CR \
>   --pre_trained_model HAZE4K/HAZE4K_fused.pkl \
>   --save_infer_results
[i 1219 13:16:31.608887 04 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:16:31.610679 04 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:16:31.610728 04 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:16:31.648976 04 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:16:31.649146 04 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['eval.py', '--dataset', 'HAZE4K', '--model_name', 'DEA-Net-CR', '--pre_trained_model', 'HAZE4K/HAZE4K_fused.pkl', '--save_infer_results']
[i 1219 13:16:31.705272 52 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:16:31.707000 52 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:16:31.707044 52 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:16:31.744286 52 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:16:31.750363 52 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:16:31.765884 52 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:16:31.819105 52 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:16:32.245333 52 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:16:32.348156 52 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:16:32.523288 52 init.cc:63] Found cuda archs: [86,]
Option saved. Inference dir: ../experiment/HAZE4K/DEA-Net-CR/HAZE4K_fused
Traceback (most recent call last):
  File "eval.py", line 12, in <module>
    from models.backbone import Backbone # 假设 Backbone 保存在 models/backbone.py
ModuleNotFoundError: No module named 'models'
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# python3 eval.py \
el_name DEA-Net->    --dataset HAZE4K \
>    --model_name DEA-Net-CR \
>    --pre_trained_model HAZE4K_fused.pkl \
>    --save_infer_results
[i 1219 13:17:16.768756 92 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:17:16.770277 92 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:17:16.770322 92 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:17:16.808276 92 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:17:16.808436 92 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['eval.py', '--dataset', 'HAZE4K', '--model_name', 'DEA-Net-CR', '--pre_trained_model', 'HAZE4K_fused.pkl', '--save_infer_results']
[i 1219 13:17:16.864060 96 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:17:16.865627 96 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:17:16.865670 96 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:17:16.896222 96 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:17:16.898437 96 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:17:16.911292 96 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:17:16.962152 96 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:17:17.211568 96 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:17:17.263328 96 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:17:17.432016 96 init.cc:63] Found cuda archs: [86,]
Option saved. Inference dir: ../experiment/HAZE4K/DEA-Net-CR/HAZE4K_fused
Traceback (most recent call last):
  File "eval.py", line 12, in <module>
    from models.backbone import Backbone # 假设 Backbone 保存在 models/backbone.py
ModuleNotFoundError: No module named 'models'
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# dir
__pycache__  eval.py       inference_raw.py  loss    model   option_train.py  train.py
data         inference.py  logger            metric  option  reparam.py       utils
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# cd model
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code/model# dir
__init__.py  __pycache__  backbone.py  backbone_train.py  modules
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code/model# cd modules
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code/model/modules# dir
__init__.py  __pycache__  cga.py  deablock.py  deablock_train.py  deconv.py  fusion.py
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code/model/modules# cd ..
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code/model# cd ..
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# python3 eval.py \
>    --dataset HAZE4K \
>    --model_name DEA-Net-CR \
>    --pre_trained_model HAZE4K_fused.pkl \
>    --save_infer_results
[i 1219 13:25:35.799964 64 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:25:35.801625 64 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:25:35.801669 64 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:25:35.840851 64 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:25:35.841002 64 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['eval.py', '--dataset', 'HAZE4K', '--model_name', 'DEA-Net-CR', '--pre_trained_model', 'HAZE4K_fused.pkl', '--save_infer_results']
[i 1219 13:25:35.895455 28 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:25:35.897168 28 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:25:35.897213 28 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:25:35.928285 28 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:25:35.930451 28 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:25:35.944203 28 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:25:35.994264 28 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:25:36.226658 28 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:25:36.280316 28 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:25:36.420131 28 init.cc:63] Found cuda archs: [86,]
Option saved. Inference dir: ../experiment/HAZE4K/DEA-Net-CR/HAZE4K_fused
Traceback (most recent call last):
  File "eval.py", line 15, in <module>
    from model.backbone import Backbone
  File "/root/Jittor-DEA-Net/code/model/__init__.py", line 1, in <module>
    from .backbone import Backbone
  File "/root/Jittor-DEA-Net/code/model/backbone.py", line 5, in <module>
    from .deablock import DEBlock, DEABlock
ModuleNotFoundError: No module named 'model.deablock'
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# python3 eval.py \
>    --dataset HAZE4K \
>    --model_name DEA-Net-CR \
>    --pre_trained_model HAZE4K_fused.pkl \
>    --save_infer_results
[i 1219 13:34:54.819974 60 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:34:54.821797 60 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:34:54.821842 60 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:34:54.858374 60 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:34:54.858537 60 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['eval.py', '--dataset', 'HAZE4K', '--model_name', 'DEA-Net-CR', '--pre_trained_model', 'HAZE4K_fused.pkl', '--save_infer_results']
[i 1219 13:34:54.912877 24 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:34:54.914477 24 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:34:54.914521 24 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:34:54.949272 24 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:34:54.951659 24 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:34:54.965377 24 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:34:55.016167 24 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:34:55.246195 24 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:34:55.297816 24 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:34:55.476958 24 init.cc:63] Found cuda archs: [86,]
Option saved. Inference dir: ../experiment/HAZE4K/DEA-Net-CR/HAZE4K_fused
[i 1219 13:34:56.211593 24 cuda_flags.cc:55] CUDA enabled.
Traceback (most recent call last):
  File "eval.py", line 81, in <module>
    val_dataset = ValDataset(os.path.join(opt.val_dataset_dir, 'hazy'), os.path.join(opt.val_dataset_dir, 'clear'))
  File "/root/Jittor-DEA-Net/code/data/data_loader.py", line 90, in __init__
    self.hazy_image_list = sorted(os.listdir(hazy_path))
FileNotFoundError: [Errno 2] No such file or directory: '../dataset/HAZE4K/test/hazy'
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# python3 eval.py \
>    --dataset HAZE4K \
>    --model_name DEA-Net-CR \
>    --pre_trained_model HAZE4K_fused.pkl \
>    --save_infer_results
[i 1219 13:35:17.504538 76 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:35:17.506274 76 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:35:17.506335 76 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:35:17.546327 76 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:35:17.546501 76 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['eval.py', '--dataset', 'HAZE4K', '--model_name', 'DEA-Net-CR', '--pre_trained_model', 'HAZE4K_fused.pkl', '--save_infer_results']
[i 1219 13:35:17.602625 24 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:35:17.604312 24 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:35:17.604393 24 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:35:17.637372 24 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:35:17.639545 24 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:35:17.653413 24 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:35:17.704433 24 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:35:17.942398 24 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:35:17.998368 24 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:35:18.172442 24 init.cc:63] Found cuda archs: [86,]
Option saved. Inference dir: ../experiment/HAZE4K/DEA-Net-CR/HAZE4K_fused
[i 1219 13:35:18.881315 24 cuda_flags.cc:55] CUDA enabled.
Loading model from: ../trained_models/HAZE4K/HAZE4K_fused.pkl
evaluation:   0%|                                                                              | 0/1000 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "eval.py", line 110, in <module>
    avg_psnr, avg_ssim = eval(val_dataset, network)
  File "eval.py", line 57, in eval
    save_image(output, save_path)
  File "/root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor/misc.py", line 536, in save_image
    ndarr = (grid*255+0.5).clamp(0, 255).permute(1, 2, 0).uint8().numpy()
  File "/root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor/__init__.py", line 699, in transpose
    return origin_transpose(x, dim)
RuntimeError: Wrong inputs arguments, Please refer to examples(help(jt.ops.transpose)).

Types of your inputs are:
 self   = module,
 args   = (Var, tuple, ),

The function declarations are:
 VarHolder* transpose(VarHolder* x,  NanoVector axes=NanoVector())

Failed reason:[f 1219 13:35:22.603635 24 fuse_transpose_op.cc:59] Check failed axes.size()(3) == xdim(4)
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# python3 eval.py \
>    --dataset HAZE4K \
>    --model_name DEA-Net-CR \
>    --pre_trained_model HAZE4K_fused.pkl \
>    --save_infer_results
[i 1219 13:38:26.555036 52 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:38:26.556675 52 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:38:26.556743 52 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:38:26.591518 52 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:38:26.591695 52 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['eval.py', '--dataset', 'HAZE4K', '--model_name', 'DEA-Net-CR', '--pre_trained_model', 'HAZE4K_fused.pkl', '--save_infer_results']
[i 1219 13:38:26.648005 00 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:38:26.649716 00 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:38:26.649764 00 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:38:26.681735 00 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:38:26.687798 00 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:38:26.703100 00 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:38:26.755654 00 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:38:27.172561 00 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:38:27.273242 00 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:38:27.464858 00 init.cc:63] Found cuda archs: [86,]
Option saved. Inference dir: ../experiment/HAZE4K/DEA-Net-CR/HAZE4K_fused
[i 1219 13:38:28.751245 00 cuda_flags.cc:55] CUDA enabled.
Loading model from: ../trained_models/HAZE4K/HAZE4K_fused.pkl
evaluation:   0%|                                                                              | 0/1000 [00:00<?, ?it/s]
Compiling Operators(31/31) used: 10.3s eta:    0s

Compiling Operators(7/7) used: 4.31s eta:    0s
evaluation:   0%|                                                                    | 1/1000 [00:20<5:39:27, 20.39s/it]
Compiling Operators(4/4) used: 2.31s eta:    0s
evaluation: 100%|███████████████████████████████████████████████████████████████████| 1000/1000 [02:11<00:00,  7.61it/s]
Evaluation on HAZE4K
PSNR:23.89582241381554
SSIM:0.9264533236622811
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# python3 eval.py \
> >    --dataset HAZE4K \
> >    --model_name DEA-Net-CR \
> >    --pre_trained_model HAZE4K_fused.pkl \
> >    --save_infer_results
[i 1219 13:45:08.851643 12 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:45:08.853387 12 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:45:08.853434 12 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:45:08.891309 12 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:45:08.891481 12 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['eval.py', 'HAZE4K', 'DEA-Net-CR', 'HAZE4K_fused.pkl']
[i 1219 13:45:08.947739 36 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:45:08.949475 36 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:45:08.949516 36 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:45:08.982685 36 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:45:08.985398 36 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:45:08.999361 36 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:45:09.053273 36 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:45:09.298041 36 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:45:09.352729 36 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:45:09.537169 36 init.cc:63] Found cuda archs: [86,]
usage: eval.py [-h] [--exp_dir EXP_DIR] [--dataset DATASET]
               [--val_dataset_dir VAL_DATASET_DIR] [--model_name MODEL_NAME]
               [--saved_infer_dir SAVED_INFER_DIR]
               [--pre_trained_model PRE_TRAINED_MODEL] [--save_infer_results]
eval.py: error: unrecognized arguments: HAZE4K DEA-Net-CR HAZE4K_fused.pkl
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# python3 eval.py \
>    --dataset HAZE4K \
>    --model_name DEA-Net-CR \
>    --pre_trained_model HAZE4K_fused.pkl \
>    --save_infer_results
[i 1219 13:46:30.603139 12 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:46:30.604843 12 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:46:30.604886 12 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:46:30.643402 12 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:46:30.643606 12 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['eval.py', '--dataset', 'HAZE4K', '--model_name', 'DEA-Net-CR', '--pre_trained_model', 'HAZE4K_fused.pkl', '--save_infer_results']
[i 1219 13:46:30.700984 04 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 13:46:30.702782 04 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 13:46:30.702830 04 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 13:46:30.735764 04 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 13:46:30.738009 04 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 13:46:30.751847 04 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 13:46:30.802584 04 compiler.py:1013] cuda key:cu12.2.140
[i 1219 13:46:31.035025 04 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 13:46:31.085371 04 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 13:46:31.239198 04 init.cc:63] Found cuda archs: [86,]
Option saved. Inference dir: ../experiment/HAZE4K/DEA-Net-CR/HAZE4K_fused
[i 1219 13:46:31.962423 04 cuda_flags.cc:55] CUDA enabled.
Loading model from: ../trained_models/HAZE4K/HAZE4K_fused.pkl
evaluation:   0%|                                                                              | 0/1000 [00:00<?, ?it/s]
Compiling Operators(30/30) used: 2.31s eta:    0s
evaluation: 100%|███████████████████████████████████████████████████████████████████| 1000/1000 [01:46<00:00,  9.36it/s]
Evaluation on HAZE4K
PSNR:34.25671330115773
SSIM:0.9872655354738236
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# python3 eval.py \
>    --dataset ITS \
>    --model_name DEA-Net-CR \
>    --pre_trained_model ITS_fused.pkl \
>    --save_infer_results
[i 1219 14:03:29.257082 12 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 14:03:29.258639 12 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 14:03:29.258683 12 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 14:03:29.306657 12 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 14:03:29.306829 12 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['eval.py', '--dataset', 'ITS', '--model_name', 'DEA-Net-CR', '--pre_trained_model', 'ITS_fused.pkl', '--save_infer_results']
[i 1219 14:03:29.363143 96 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 14:03:29.364829 96 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 14:03:29.364877 96 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 14:03:29.407073 96 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 14:03:29.413284 96 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 14:03:29.430548 96 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 14:03:29.483238 96 compiler.py:1013] cuda key:cu12.2.140
[i 1219 14:03:29.902634 96 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 14:03:30.003103 96 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 14:03:30.181970 96 init.cc:63] Found cuda archs: [86,]
Option saved. Inference dir: ../experiment/ITS/DEA-Net-CR/ITS_fused
[i 1219 14:03:31.481477 96 cuda_flags.cc:55] CUDA enabled.
Loading model from: ../trained_models/ITS/ITS_fused.pkl
evaluation:   0%|                                                                               | 0/500 [00:00<?, ?it/s]
Compiling Operators(30/30) used: 3.31s eta:    0s
evaluation: 100%|█████████████████████████████████████████████████████████████████████| 500/500 [01:10<00:00,  7.06it/s]
Evaluation on ITS
PSNR:41.30752143671612
SSIM:0.9963942694664002
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# python3 eval.py \
>    --dataset OTS \
>    --model_name DEA-Net-CR \
>    --pre_trained_model OTS_fused.pkl \
ve_infer_results>    --save_infer_results
[i 1219 14:04:59.835306 76 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 14:04:59.836868 76 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 14:04:59.836915 76 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 14:04:59.869565 76 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 14:04:59.869732 76 install_cuda.py:84] restart /root/anaconda3/envs/jittor_env/bin/python3 ['eval.py', '--dataset', 'OTS', '--model_name', 'DEA-Net-CR', '--pre_trained_model', 'OTS_fused.pkl', '--save_infer_results']
[i 1219 14:04:59.925924 52 compiler.py:956] Jittor(1.3.10.0) src: /root/anaconda3/envs/jittor_env/lib/python3.8/site-packages/jittor
[i 1219 14:04:59.927567 52 compiler.py:957] g++ at /usr/bin/g++(9.4.0)
[i 1219 14:04:59.927611 52 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.10/g++9.4.0/py3.8.20/Linux-6.6.87.2x55/13thGenIntelRCx97/7dfa/default
[i 1219 14:04:59.963305 52 install_cuda.py:96] cuda_driver_version: [12, 6]
[i 1219 14:04:59.965856 52 __init__.py:412] Found /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc(12.2.140) at /root/.cache/jittor/jtcuda/cuda12.2_cudnn8_linux/bin/nvcc.
[i 1219 14:04:59.979377 52 __init__.py:412] Found addr2line(2.34) at /usr/bin/addr2line.
[i 1219 14:05:00.033785 52 compiler.py:1013] cuda key:cu12.2.140
[i 1219 14:05:00.261698 52 __init__.py:227] Total mem: 31.23GB, using 10 procs for compiling.
[i 1219 14:05:00.316509 52 jit_compiler.cc:28] Load cc_path: /usr/bin/g++
[i 1219 14:05:00.490189 52 init.cc:63] Found cuda archs: [86,]
Option saved. Inference dir: ../experiment/OTS/DEA-Net-CR/OTS_fused
[i 1219 14:05:01.207259 52 cuda_flags.cc:55] CUDA enabled.
Loading model from: ../trained_models/OTS/OTS_fused.pkl
evaluation:   0%|                                                                               | 0/500 [00:00<?, ?it/s]
Compiling Operators(30/30) used: 2.32s eta:    0s
evaluation:   0%|▏                                                                      | 1/500 [00:05<43:07,  5.19s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:   1%|▍                                                                      | 3/500 [00:08<20:08,  2.43s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:   2%|█▍                                                                    | 10/500 [00:11<06:07,  1.33it/s]
Compiling Operators(4/4) used: 2.31s eta:    0s
evaluation:   2%|█▋                                                                    | 12/500 [00:14<07:59,  1.02it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:   5%|███▋                                                                  | 26/500 [00:18<02:10,  3.64it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:   6%|████                                                                  | 29/500 [00:23<05:38,  1.39it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
[w 1219 14:05:28.285698 52 cudnn_conv__Tx_float32__Ty_float32__Tw_float32__XFORMAT_abcd__WFORMAT_oihw__YFORMAT_abcd_____hash_4d5b3e2d24c769d3_op.cc:214] forward_ algorithm cache is full
evaluation:   7%|████▌                                                                 | 33/500 [00:27<05:48,  1.34it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:   7%|████▉                                                                 | 35/500 [00:29<06:35,  1.18it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:   8%|█████▉                                                                | 42/500 [00:38<08:16,  1.08s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  10%|███████▎                                                              | 52/500 [00:45<05:00,  1.49it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  12%|████████                                                              | 58/500 [00:48<03:04,  2.39it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  12%|████████▍                                                             | 60/500 [00:50<04:48,  1.53it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  12%|████████▋                                                             | 62/500 [00:53<06:11,  1.18it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  14%|█████████▊                                                            | 70/500 [00:58<04:27,  1.61it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  15%|██████████▏                                                           | 73/500 [01:02<07:00,  1.02it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  15%|██████████▎                                                           | 74/500 [01:05<08:58,  1.26s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  16%|███████████                                                           | 79/500 [01:08<05:04,  1.38it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  16%|███████████▎                                                          | 81/500 [01:10<06:08,  1.14it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  17%|███████████▊                                                          | 84/500 [01:15<07:46,  1.12s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  17%|███████████▉                                                          | 85/500 [01:18<09:46,  1.41s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  17%|████████████▏                                                         | 87/500 [01:20<09:26,  1.37s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  18%|████████████▌                                                         | 90/500 [01:23<07:54,  1.16s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  19%|█████████████                                                         | 93/500 [01:25<07:05,  1.04s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  20%|█████████████▋                                                        | 98/500 [01:28<04:57,  1.35it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  20%|█████████████▊                                                       | 100/500 [01:31<05:54,  1.13it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  20%|█████████████▉                                                       | 101/500 [01:33<07:39,  1.15s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  20%|██████████████                                                       | 102/500 [01:36<09:23,  1.42s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  21%|██████████████▍                                                      | 105/500 [01:39<07:46,  1.18s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  36%|████████████████████████▊                                            | 180/500 [01:52<01:28,  3.60it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  38%|█████████████████████████▉                                           | 188/500 [01:57<02:14,  2.32it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  52%|███████████████████████████████████▉                                 | 260/500 [02:05<00:43,  5.54it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  59%|████████████████████████████████████████▌                            | 294/500 [02:11<00:35,  5.83it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  60%|█████████████████████████████████████████▌                           | 301/500 [02:14<00:48,  4.08it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  61%|█████████████████████████████████████████▉                           | 304/500 [02:18<01:55,  1.70it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  62%|██████████████████████████████████████████▋                          | 309/500 [02:23<02:18,  1.38it/s]
Compiling Operators(3/3) used: 2.32s eta:    0s
evaluation:  63%|███████████████████████████████████████████▎                         | 314/500 [02:26<01:46,  1.75it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  71%|█████████████████████████████████████████████████▏                   | 356/500 [02:34<00:08, 16.06it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  73%|██████████████████████████████████████████████████▋                  | 367/500 [02:39<00:31,  4.28it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  74%|███████████████████████████████████████████████████                  | 370/500 [02:42<00:53,  2.44it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  82%|████████████████████████████████████████████████████████▊            | 412/500 [02:46<00:03, 24.38it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  84%|█████████████████████████████████████████████████████████▉           | 420/500 [02:48<00:13,  5.85it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  85%|██████████████████████████████████████████████████████████▊          | 426/500 [02:51<00:19,  3.77it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  91%|███████████████████████████████████████████████████████████████      | 457/500 [02:57<00:02, 15.66it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  93%|████████████████████████████████████████████████████████████████▍    | 467/500 [03:06<00:15,  2.16it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  94%|████████████████████████████████████████████████████████████████▊    | 470/500 [03:11<00:22,  1.31it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  94%|█████████████████████████████████████████████████████████████████▏   | 472/500 [03:13<00:24,  1.14it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  95%|█████████████████████████████████████████████████████████████████▌   | 475/500 [03:18<00:27,  1.12s/it]
Compiling Operators(3/3) used: 2.32s eta:    0s
evaluation:  95%|█████████████████████████████████████████████████████████████████▋   | 476/500 [03:20<00:32,  1.37s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  95%|█████████████████████████████████████████████████████████████████▊   | 477/500 [03:23<00:36,  1.59s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
[w 1219 14:08:27.141965 52 cudnn_conv_backward_x__Tx_float32__Ty_float32__Tw_float32__XFORMAT_abcd__WFORMAT_oihw__YFO___hash_af8994a8aef53c1c_op.cc:206] backward x algorithm cache is full
evaluation:  96%|██████████████████████████████████████████████████████████████████▍  | 481/500 [03:28<00:25,  1.36s/it]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation:  98%|███████████████████████████████████████████████████████████████████▊ | 491/500 [03:31<00:03,  2.85it/s]
Compiling Operators(3/3) used: 2.31s eta:    0s
evaluation: 100%|█████████████████████████████████████████████████████████████████████| 500/500 [03:33<00:00,  2.34it/s]
Evaluation on OTS
PSNR:35.96872828696171
SSIM:0.9910935324430465
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# CUDA_VISIBLE_DEVICES=0 nohup python3 train.py \
>   --epochs 10 \
>   --iters_per_epoch 5000 \
>   --finer_eval_step 1400000 \
>   --w_loss_L1 1.0 \
>   --w_loss_CR 0.1 \
>   --start_lr 0.0001 \
>   --end_lr 0.000001 \
>   --exp_dir ../experiment/ \
>   --model_name DEA-Net-CR-HAZE4K \
>   --dataset HAZE4K \
>   --bs 8 \
> ^C
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code#
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# CUDA_VISIBLE_DEVICES=0 nohup python train.py \
> --epochs 10 \
> --iters_per_epoch 5000 \
> --finer_eval_step 1400000 \
> --w_loss_L1 1.0 \
> --w_loss_CR 0.1 \
> --start_lr 0.0001 \
> --end_lr 0.000001 \
> --exp_dir ../experiment/ \
> --model_name DEA-Net-CR-HAZE4K \
> --dataset HAZE4K \
> > training_haze4k.log 2>&1 &
[1] 302286
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# dir
__pycache__  eval.py       inference_raw.py  loss    model   option_train.py  train.py             utils
data         inference.py  logger            metric  option  reparam.py       training_haze4k.log
[1]+  Exit 1                  CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 10 --iters_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir ../experiment/ --model_name DEA-Net-CR-HAZE4K --dataset HAZE4K > training_haze4k.log 2>&1
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# cd utils
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code/utils# dir
__init__.py  __pycache__  metric.py  utils.py
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code/utils# cd ..
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 10 --iters_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir ../experiment/ --model_name DEA-Net-CR-HAZE4K --dataset HAZE4K > training_haze4k.log 2>&1 &
[1] 308887
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 10 --iters_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir ../experiment/ --model_name DEA-Net-CR-HAZE4K --dataset HAZE4K > training_haze4k.log 2>&1 &
[2] 314258
[1]   Exit 1                  CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 10 --iters_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir ../experiment/ --model_name DEA-Net-CR-HAZE4K --dataset HAZE4K > training_haze4k.log 2>&1
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 10 --iters_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir ../experiment/ --model_name DEA-Net-CR-HAZE4K --dataset HAZE4K > training_haze4k.log 2>&1 &
[3] 316032
[2]   Exit 1                  CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 10 --iters_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir ../experiment/ --model_name DEA-Net-CR-HAZE4K --dataset HAZE4K > training_haze4k.log 2>&1
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# CUDA_VISIBLE_DEVICES=0 nohup python train.py \
[3]+  Done                    CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 10 --iters_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir ../experiment/ --model_name DEA-Net-CR-HAZE4K --dataset HAZE4K > training_haze4k.log 2>&1
> --epochs 10 \
> --iters_per_epoch 5000 \
> --finer_eval_step 1400000 \
> --w_loss_L1 1.0 \
> --w_loss_CR 0.1 \
> --start_lr 0.0001 \
> --end_lr 0.000001 \
> --exp_dir ../experiment/ \
> --model_name DEA-Net-CR-ITS \
> --dataset ITS \
> > training_its.log 2>&1 &
[1] 528496
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# CUDA_VISIBLE_DEVICES=0 nohup python train.py \
-epochs 10 \
--i[1]+  Done                    CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 10 --iters_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir ../experiment/ --model_name DEA-Net-CR-ITS --dataset ITS > training_its.log 2>&1
> --epochs 10 \
> --iters_per_epoch 5000 \
> --finer_eval_step 1400000 \
> --w_loss_L1 1.0 \
> --w_loss_CR 0.1 \
> --start_lr 0.0001 \
> --end_lr 0.000001 \
> --exp_dir ../experiment/ \
> --model_name DEA-Net-CR-OTS \
 OTS \
> training_ots.log 2>&1 &> --dataset OTS \
> > training_ots.log 2>&1 &
[1] 746133
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# ^C
[1]+  Exit 1                  CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 10 --iters_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir ../experiment/ --model_name DEA-Net-CR-OTS --dataset OTS > training_ots.log 2>&1
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# CUDA_VISIBLE_DEVICES=0 nohup python train.py \
> --epochs 10 \
> --iters_per_epoch 5000 \
> --finer_eval_step 1400000 \
> --w_loss_L1 1.0 \
> --w_loss_CR 0.1 \
> --start_lr 0.0001 \
> --end_lr 0.000001 \
> --exp_dir ../experiment/ \
_name DEA-Net-CR> --model_name DEA-Net-CR-OTS \
> --dataset OTS \
> > training_ots.log 2>&1 &
[1] 751329
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code# CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 30 --iter
s_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir
 ../experiment/ --model_name DEA-Net-CR-HAZE4K --dataset HAZE4K > training_haze4k.log 2>&1 &
[2] 933235
[1]   Done                    CUDA_VISIBLE_DEVICES=0 nohup python train.py --epochs 10 --iters_per_epoch 5000 --finer_eval_step 1400000 --w_loss_L1 1.0 --w_loss_CR 0.1 --start_lr 0.0001 --end_lr 0.000001 --exp_dir ../experiment/ --model_name DEA-Net-CR-OTS --dataset OTS > training_ots.log 2>&1
(jittor_env) root@DESKTOP-JGV50N5:~/Jittor-DEA-Net/code#